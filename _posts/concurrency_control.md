# 事务的深入以及数据库并发控制初识

在上一篇文章[数据库事务及sequelize.transaction实践](https://github.com/caistrong/Blog/issues/104)中，我们简单地介绍了一下事务在具体业务逻辑中的应用，以及具体的使用sequelize.transaction的方式。然而在[sequelize.transaction官方文档](http://docs.sequelizejs.com/manual/tutorial/transactions.html#options)里我们看到了options里可以全局地或者局部地设定事务的隔离型等级isolationLevel，默认的值是REPEATABLE_READ(可重复读)。这个所谓隔离性等级是什么意思有什么作用呢?下面我会细细地讲一下我的理解。

## 事务

*以下内容来自[维基百科【数据库事务】](https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1)*

- 定义

数据库事务（简称：事务）是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。

- 目的

一个数据库事务通常包含了一个序列的对数据库的读/写操作。它的存在包含有以下两个目的：

1. 为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。

2. 当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。

## ACID特性

事务应该具有4个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为ACID特性。先来看一下[维基百科【ACID】](https://zh.wikipedia.org/wiki/ACID)对ACID的定义

- Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被恢复（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。
- Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。
- Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。
- Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

## 关于ACID的一点理解

通常定义本身会较为权威并且严谨不会出错。但是只看文邹邹的定义可能有点难以理解，这里提出我的一点理解，与定义相对的是我的理解可能出错或缺乏严谨性，请批判性地阅读，并欢迎提出看法。

我们考虑一下上文王健林转账1亿给我帮我实现小目标的故事，我们在数据库操作层面上细化一下这件事执行的步骤：

1. 从王健林的账户中把余额读出来（1000亿）。
2. 对王健林的账户账号做减法操作（1000亿-1亿）。
3. 把结果写回王健林的账户中（999亿）。
4. 从我的账户中把余额读出来（0亿）。
5. 对我的账户做加法操作（0亿+1亿）。
6. 把结果写回我的账户中（1亿）。

- Atomicity（原子性）：

根据上文对于事务的定义（事务...由一个有限的数据库操作序列构成）,可以理解上面这1-6的步骤就是一个事务，原子性必须保证这6个步骤只能全部完成或者全部不完成，不可分割。关于原子性，相信根据上一篇文章[数据库事务及sequelize.transaction实践](https://github.com/caistrong/Blog/issues/104)里的具体业务逻辑的例子。大家应该能理解该特性存在的价值。本文不会再赘述该特性在业务逻辑侧的应用和其存在的必要性。

- Consistency（一致性）：

把一致性的定义换一种话说，就是在事务开始之前，和事务结束之后，数据库必须满足[完整性约束](https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7%E7%BA%A6%E6%9D%9F)。我觉得一致性这个特性更像是一种结果，而不是条件。

比如原子性在某些时候就是保障一致性这个结果的一种条件。在极端情况下考虑，该银行下只有王健林和我两个账户。并且所有的操作仅限王健林给我转钱或者我给王健林转钱。此时我们可以对这个银行数据库做一个自定义的完整性约束：所有账户的余额加起来必须为1000亿。这个完整性对于当前的业务逻辑是合理的。因为不管我和王健林怎么互转操作，我们之间账户总额应该都是1000亿。这时候如果某一次王健林给我砖1亿的操作这个事务在第3或第4步事务突然失败【原因例如我的账户在这个瞬间被银行冻结了】。并且没有回滚到转账事务开始之前，也就是没有满足原子性。那么此时这1亿就不翼而飞了。我和王健林账户余额加起来变成了999亿。破坏了完整性约束。也就导致了一致性也没得到满足。所以这个例子就是因为原子性条件没有满足，导致了一致性也没满足。

除了原子性以外，我觉得隔离性也可以理解是保障一致性的重要条件。

[如何理解数据库事务中的一致性的概念? 孟波的回答](https://www.zhihu.com/question/31346392/answer/362597203)

- Isolation（隔离性）

我觉得隔离性是并发控制的主要内容，隔离性将是今天的主角。在下面讲脏读(Dirty Read)、不可重复读(Non-Repeatable Read)、幻读(Phantom Read)这些读现象，以及介绍事务隔离层级之后，会更理解隔离性。在这里先简单下一个结论：

事务的最高隔离级别（串行化）可以保障强一致性。而如果采用读未提交这类的低隔离级别，一致性不如串行化，但是却可以提升系统的性能与并行度(并行能力)

- Durability（持久性）

这一点我觉得没什么好说的，持久性的保障应该更多来自于编写数据库管理软件系统的程序员甚至是更底层的在物理层面保障，我们这种数据库的使用者能做的不多。当然持久性的保障也是一致性的前提。

## 数据库并发控制初识

我觉得并发控制是一个极其复杂和广泛的问题，在网络上浏览相关的文章越多，越感觉自己理解的渺小。所以这里仅做一点简单地了解

## 事务并发执行可能带来的状况（数据库的读现象）

在讲并发控制之前我想先讲一下为什么并发需要“控制”，既然是控制，那么肯定是有我们意想不到的或者不希望发生的状况出现，我们才需要控制。这些状况主要就是数据库的读现象，包含脏读、不可重复读、幻读。

### 脏读

脏读又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。

脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交(commit)到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是脏数据，依据脏数据所做的操作可能是不正确的。

事务T1| 事务T2
------|--------                                                     
UPDATE users SET age = 21 WHERE id = 1;<br>/* No commit here */|   
 &nbsp; |  SELECT age FROM users WHERE id = 1;<br>/* will read 21*/ 
ROLLBACK;<br>/* lock-based DIRTY READ */ |  
    
在这个例子中，假设我们初识时id=1的用户age=20，由于事务T1的更新操作最终没有COMMIT而是ROLLBACK了，因此事务T2读到的id=1 age=21的这一条是脏数据

### 不可重复读

不可重复读，是指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而引起的。比如事务T1读取某一数据，事务T2读取并修改了该数据，T1为了对读取值进行检验而再次读取该数据，便得到了不同的结果。

一种更易理解的说法是：在一个事务内，多次读同一个数据。在这个事务还没有结束时，另一个事务也访问该同一数据。那么，在第一个事务的两次读数据之间。由于第二个事务的修改，那么第一个事务读到的数据可能不一样，这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读，即原始读取不可重复。

事务T1| 事务T2
------|--------                                                     
SELECT * FROM users WHERE id = 1;<br>/* No commit here */ |
&nbsp; |  UPDATE users SET age = 21 WHERE id = 1;<br>COMMIT;<br>/* in multiversion concurrency control, or lock-based READ COMMITTED */
SELECT * FROM users WHERE id = 1;<br>COMMIT;<br>/*lock-based REPEATABLE READ */ |  

在基于锁的并发控制中“不可重复读(non-repeatable read)”现象发生在当执行SELECT 操作时没有获得读锁(read locks)或者SELECT操作执行完后马上释放了读锁； 多版本并发控制中当没有要求一个提交冲突的事务回滚也会发生“不可重复读(non-repeatable read)”现象。

在这个例子中，事务2提交成功，因此他对id为1的行的修改就对其他事务可见了。但是事务1在此前已经从这行读到了另外一个“age”的值。

### 幻读

幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样.一般解决幻读的方法是增加范围锁RangeS，锁定检锁范围为只读，这样就避免了幻读。　

幻读是不可重复读的一种特殊场景：当事务没有获取范围锁的情况下执行SELECT … WHERE操作可能会发生幻影读。

事务T1| 事务T2
------|--------                                                     
SELECT * FROM users WHERE age BETWEEN 10 AND 30;<br>/* No commit here */ |
&nbsp; |  INSERT INTO users VALUES ( 3, 'Bob', 27 );<br>COMMIT;
SELECT * FROM users WHERE age BETWEEN 10 AND 30;<br>COMMIT;|  

当事务1两次执行SELECT … WHERE检索一定范围内数据的操作中间，事务2在这个表中创建了(如INSERT)了一行新数据，这条新数据正好满足事务1的“WHERE”子句。

在这个例子中，事务一执行了两次相同的查询操作。但是两次操作中间事务二向数据库中增加了一条符合事务一的查询条件的数据，导致幻读。

## 事务隔离级别

要想解决脏读、不可重复读、幻读等读现象，那么就需要提高事务的隔离级别。这里就关系到ACID中的隔离性，数据库的隔离级别按ANSI/ISO SQL定义的标准有四种，从高到低依次为：可序列化(Serializable)、可重复读(Repeatable reads)、提交读(Read committed)、未提交读(Read uncommitted)。


### 锁🔒

在深入讲事务隔离级别之前，我觉得应该先了解一下锁。因为在解决上述读现象的状况时，实际上采用的策略是基于锁的并发控制。**在我看来所谓的隔离级别只不过是根据对不同锁的使用构成的集合的代称而已**。比如未提交读就是代指【事务在读数据时不加锁，写数据时只加行级共享锁】等等。后续会详细介绍

网上关于锁的各种说法实在太多太多了，什么乐观锁、悲观锁、意向锁、互斥锁、表级锁、行级锁，行级共享锁，还有把互斥锁翻译成排他锁。看得我头皮发麻。

这里我忽略与当前主题无关的锁的概念，简单按两种方式来分类锁

1. 按锁定粒度分为

- 行级锁（锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。开销大，加锁慢；会出现死锁；锁定粒度最小，
发生锁冲突的概率最低，并发度也最高。）

- 表级锁（锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低）

- 页级锁（锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录，开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般）

2. 按锁的级别分为

- 共享锁(Share Lock)

```sql
SELECT ... LOCK IN SHARE MODE;
```

共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的互斥锁），直到已释放所有共享锁。

如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加互斥锁。获准共享锁的事务只能读数据，不能修改数据。


- 互斥锁（eXclusive Lock）*或译为排他锁*

```sql
SELECT ... FOR UPDATE;
```

互斥锁(排他锁)又称写锁，如果事务T对数据A加上互斥锁后，则其他事务不能再对A加任任何类型的封锁。获准互斥锁的事务既能读数据，又能修改数据。

*这两种分类互不冲突，可正交，因此就有行级共享锁、表级互斥锁之类的概念*

### 未提交读(Read uncommitted)

> **未提交读的数据库锁情况** <br>事务在读数据的时候并未对数据加锁。<br>事务在修改数据的时候只对数据增加行级共享锁。

未提交读(READ UNCOMMITTED)是最低的隔离级别。在这种事务隔离级别下，一个事务可以读到另外一个事务未提交的数据。这会导致前面读现象所说的**脏读**状况

在刚刚**脏读**中举的例子

事务T1| 事务T2
------|--------                                                     
UPDATE users SET age = 21 WHERE id = 1;<br>/* No commit here */|   
 &nbsp; |  SELECT age FROM users WHERE id = 1;<br>/* will read 21*/ 
ROLLBACK;<br>/* lock-based DIRTY READ */ |  

事务T1在更新这条记录的时候，只对该记录加了行级共享锁，这时候事务T2读取该记录，也能再加行级共享锁来读取数据。因此就读到了未提交的脏数据。

这里我们会想，为啥事务T1在更新这条记录的时候不给该记录加行级互斥锁呢？这样事务T2不就不能来加共享锁读取数据了，没错，这就是提交读的思路

### 提交读(Read committed)

> **提交读的数据库锁情况** <br> 事务对当前被读取的数据加 行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；<br> 事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级互斥锁，直到事务结束才释放。

再啰嗦解释一下提交读：

事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取（因为事务一对该行记录增加行级共享锁的情况下，事务二同样可以对该数据增加共享锁来读数据。）。

事务1读取某行的一瞬间，事务2不能修改该行数据，但是，只要事务1读取完改行数据，事务2就可以对该行数据进行修改。（事务一在读取的一瞬间会对数据增加共享锁，任何其他事务都不能对该行数据增加互斥锁。但是事务一只要读完该行数据，就会释放行级共享锁，一旦锁释放，事务二就可以对数据增加互斥锁并修改数据）

事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。（事务一在更新数据的时候，会对该行数据增加互斥锁，知道事务结束才会释放锁，所以，在事务二没有提交之前，事务一都能不对数据增加共享锁进行数据的读取。所以，提交读可以解决**脏读**的现象）

然而提交读遇到**不可重复读**的读现象，能不能较好地解决呢？我们看看上面讲的例子：

事务T1| 事务T2
------|--------                                                     
SELECT * FROM users WHERE id = 1;<br>/* No commit here */ |
&nbsp; |  UPDATE users SET age = 21 WHERE id = 1;<br>COMMIT;<br>/* in multiversion concurrency control, or lock-based READ COMMITTED */
SELECT * FROM users WHERE id = 1;<br>COMMIT;<br>/*lock-based REPEATABLE READ */ |  

在提交读隔离级别中, 在事务二提交之前，事务一不能读取数据。只有在事务二提交之后，事务一才能读取数据。这就保证了读到的任何数据都是提交的数据，避免了脏读，但是我们看上面的例子在事务一两次读取的结果还是不一致，所以提交读不能解决**不可重复读**的读现象

### 可重复读(Repeatable reads)

> **可重复读的数据库锁情况** <br> 事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 行级共享锁，直到事务结束才释放；<br> 事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级互斥锁，直到事务结束才释放。

可重复读与上面提交读的数据库锁情况的差异关键在于**可重复读在读取瞬间加的行级共享锁等到事务结束时才释放**，而**提交读在读取瞬间加的行级共享锁在读取完之后就立即释放**

同样啰嗦解释一下可重复读：

事务1在读取某行记录的整个过程中，事务2都可以对该行记录进行读取（因为事务一对该行记录增加行级共享锁的情况下，事务二同样可以对该数据增加共享锁来读数据。）。

事务1在读取某行记录的整个过程中，事务2都不能修改该行数据（事务一在读取的整个过程会对数据增加共享锁，直到事务提交才会释放锁，所以整个过程中，任何其他事务都不能对该行数据增加互斥锁。所以，可重复读能够解决**不可重复读**的读现象）

事务1更新某行记录时，事务2不能对这行记录做更新，直到事务1结束。（事务一在更新数据的时候，会对该行数据增加互斥锁，知道事务结束才会释放锁，所以，在事务二没有提交之前，事务一都能不对数据增加共享锁进行数据的读取。所以，提交读可以解决**脏读**的现象）

*其中只有第二条和提交读不同*

这下我们再回头去看**不可重复读**的例子，可以发现可重复读的这个隔离级别已经能够解决**不可重复读**这种读现象了。这里不赘述。

那按照套路，我们来看看当可重复读遇到**幻读**现象的时候能不能很好地应对

事务T1| 事务T2
------|--------                                                     
SELECT * FROM users WHERE age BETWEEN 10 AND 30;<br>/* No commit here */ |
&nbsp; |  INSERT INTO users VALUES ( 3, 'Bob', 27 );<br>COMMIT;
SELECT * FROM users WHERE age BETWEEN 10 AND 30;<br>COMMIT;|  

在可重复读的隔离层级下，数据库执行上述并行事务的逻辑如下：

1. 事务一的第一次查询条件是`age BETWEEN 10 AND 30;`如果这是有十条记录符合条件。这时，他会给符合条件的这十条记录增加行级共享锁。任何其他事务无法更改这十条记录。

2. 事务二执行一条sql语句，语句的内容是向表中插入一条数据。因为此时没有任何事务对表增加表级锁，所以，该操作可以顺利执行。

3. 事务一再次执行`SELECT * FROM users WHERE age BETWEEN 10 AND 30;`时，结果返回的记录变成了十一条，比刚刚增加了一条，增加的这条正是事务二刚刚插入的那条。

因为没加表级锁，所以事务T1内的两次同样sql语句查询的结果不相同。幻读现象没有有效避免。

### 可序列化(Serializable)

> **可序列化的数据库锁情况** <br> 事务在读取数据时，必须先对其加 表级共享锁 ，直到事务结束才释放；<br> 事务在更新数据时，必须先对其加 表级互斥锁 ，直到事务结束才释放。

照例附上可序列化的啰嗦版本解释：

事务1正在读取A表中的记录时，则事务2也能读取A表，但不能对A表做更新、新增、删除，直到事务1结束。(因为事务一对表增加了表级共享锁，其他事务只能增加共享锁读取数据，不能进行其他任何操作）

事务1正在更新A表中的记录时，则事务2不能读取A表的任意记录，更不可能对A表做更新、新增、删除，直到事务1结束。（事务一对表增加了表级互斥锁，其他事务不能对表增加共享锁或互斥锁，也就无法进行任何操作）

我们理解产生幻读的原因是事务一在进行范围查询的时候没有增加范围锁(range-locks：给SELECT 的查询中使用一个“WHERE”子句描述范围加锁），所以导致幻读。而在**幻读**现象的例子中，如果我们采用可序列化的隔离层级。那当我们对user表10-30岁的用户进行读取的时候，可序列化规则将整个user表都加上共享锁。这个时候对user表其他任何事务都只能再加一个共享锁，所以其他事务没办法插入数据，也就避免了幻读的问题。

既然可序列化能完美解决脏读、不可重复读、幻读等读现象。但是为什么sequelize.transaction的默认隔离级别不采用可序列化而是采用可重复读呢？

一个重要的原因是我们上面讲锁的时候讲到的，加表级锁会使发生锁冲突的概率最高，并发度最低。这点不难理解，所以也不赘述。

### 没有最好的隔离级别，只有最好的选择。

四种事务隔离级别从隔离程度上越来越高，但同时在并发性上也就越来越低。之所以有这么几种隔离级别，就是为了方便开发人员在开发过程中根据业务需要选择最合适的隔离级别。

## 其他的锁🔒以及业务逻辑上的实践

当你在Google上搜索并发控制的时候，会看到很多诸如悲观锁、乐观锁、多版本并发控制(MVCC)、两阶段锁协议(2PL)、死锁等等名词。作为一个服务端开发新人。我想说对于这些概念自己向来一知半解。如果不求甚解的话，写写业务逻辑好像平时也不会遇到太多这种问题。这里有很多一部分内容。例如死锁的预防、检测和恢复的逻辑，二段锁等等。其实都是数据库管理系统已经帮我们实现和解决了。当我们使用sequelize之类的ORM库时，其实在并发控制这块，像悲观锁其实sequelize也帮我们做了。我们在options配置里设定isolationLevel或者干脆不设定采用默认的可重复读。其实也解决了大部分的并发控制问题。不过为了避免成为一个调包侠，我这里还是简单地对悲观锁和乐观锁做一个了解

### 悲观锁

悲观锁，正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度(悲观)，因此，在整个数据处理过程中，将数据处于锁定状态。 悲观锁的实现，往往依靠数据库提供的锁机制 （也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）

假设我们不使用sequelize，而是自己手写SQL语句，可能在遇到一些并发事务操作的时候我们需要手写类似如下的悲观锁逻辑

```sql
set autocommit=0; -- 需先关闭MySQL的自动提交属性
-- 0.开始事务
begin;/begin work;/start transaction; --(三者选一就可以)
-- 1.查询出商品信息
select status from t_goods where id=1 for update;
-- 2.根据商品信息生成订单
insert into t_orders (id,goods_id) values (null,1);
-- 3.修改商品status为2
update t_goods set status=2;
-- 4.提交事务
commit;/commit work;
```

`SElECT ... FOR UPDATE`会为该条数据加上一个行级互斥锁。我们通过这个手段就实现了悲观锁。然而其实如果我门使用sequelize，通过设定好隔离等级，然后传递sequelize.transaction那么我们就无须手动来做这些事。

### 乐观锁

乐观锁（ Optimistic Locking ） 相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。

相对于悲观锁，在对数据库进行处理的时候，**乐观锁并不会使用数据库提供的锁机制**。一般的实现乐观锁的方式就是记录数据版本。

乐观锁的一种简单实现方式如下：

```sql
-- 1.查询出商品信息
select (status,status,version) from t_goods where id=#{id}
-- 2.根据商品信息生成订单
-- 3.修改商品status为2
update t_goods 
set status=2,version=version+1
where id=#{id} and version=#{version};
```

我们可以发现乐观锁，其实不像上面讲的利用了什么互斥锁、共享锁这些数据库的锁机制。他其实只是一种并发控制的思想。我们为记录新增一个version字段。假设事务T1在读取该行记录的时候，version为1，此时生成订单后想要将更新该行记录的status字段，执行更新操作时，却发显找不到符合`where id=#{id} and version=#{version};`的这行记录，那么原因就是事务T1还未COMMIT的时候存在了事务T2也更新了该行记录。(*在悲观锁情况下，T1还未COMMIT的时候，T2是不能写该行记录的*)。这时候version会被T2推进1，所以找不到记录。因此判定冲突返回给用户错误信息。

*除增加version以外，Last Updated之类的字段也可以作为乐观锁的判定条件*

乐观锁更像是一种并发控制的思想。如果我们非得自己写sql语句的时候，我们可以考虑乐观锁的方式来进行并发控制。数据库管理软件，又或者是sequelize这种orm库，并没有帮我们实现乐观锁。

#### 参考资料
[hollischuang的博客](https://www.hollischuang.com/archives/category/%E6%95%B0%E6%8D%AE%E5%BA%93)
